{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from scipy.stats import ttest_ind\n",
    "from numpy import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling the Imagability data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>Imagability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>upbeat</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>recognition</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>vermin</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>waste</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>miserable</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Word    0    1    2    3    5    7    8    9   11     ...       \\\n",
       "343       upbeat  1.0  5.0  3.0  2.0  4.0  4.0  5.0  7.0  4.0     ...        \n",
       "344  recognition  3.0  5.0  2.0  3.0  4.0  3.0  1.0  7.0  3.0     ...        \n",
       "345       vermin  7.0  7.0  6.0  6.0  3.0  7.0  7.0  7.0  1.0     ...        \n",
       "346        waste  7.0  6.0  6.0  5.0  5.0  7.0  7.0  7.0  5.0     ...        \n",
       "347    miserable  2.0  6.0  5.0  4.0  4.0  4.0  6.0  7.0  5.0     ...        \n",
       "\n",
       "      51   52   53   54   55   57   58   59   60  Imagability  \n",
       "343  5.0  5.0  5.0  2.0  4.0  3.0  6.0  2.0  6.0         3.84  \n",
       "344  5.0  7.0  4.0  1.0  2.0  3.0  2.0  2.0  5.0         3.36  \n",
       "345  6.0  7.0  4.0  4.0  3.0  5.0  5.0  5.0  7.0         4.78  \n",
       "346  6.0  7.0  5.0  3.0  4.0  5.0  2.0  4.0  5.0         4.42  \n",
       "347  5.0  7.0  4.0  2.0  2.0  5.0  6.0  2.0  2.0         3.66  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 692,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_img = pd.read_csv('Stimuli/mturk_img_ratings.csv', header = 0)\n",
    "df_img = df_img[df_img.imagability_complete == 2]\n",
    "df_img = df_img.transpose()\n",
    "df_img.reset_index(level=0, inplace=True)\n",
    "df_img_just_words = df_img[3:348] # we just care about the words for now\n",
    "df_img_just_words = df_img_just_words.apply(lambda x: pd.to_numeric(x, errors='ignore')) #Need to make all rows numeric\n",
    "df_img_just_words['Imagability'] = df_img_just_words.sum(axis=1)\n",
    "df_img_just_words['Imagability'] = df_img_just_words['Imagability'].div(50)\n",
    "df_img_just_words = df_img_just_words.rename(columns={'index': 'Word'})\n",
    "df_img_just_words.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1012,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Word</th>\n",
       "      <th>MeanValence</th>\n",
       "      <th>ValenceStand</th>\n",
       "      <th>MeanArousal</th>\n",
       "      <th>type</th>\n",
       "      <th>letters</th>\n",
       "      <th>frequency</th>\n",
       "      <th>Concreteness</th>\n",
       "      <th>Img</th>\n",
       "      <th>pos</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>abandonment</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.63</td>\n",
       "      <td>4.95</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>49</td>\n",
       "      <td>2.54</td>\n",
       "      <td>3.48</td>\n",
       "      <td>noun</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ache</td>\n",
       "      <td>3.27</td>\n",
       "      <td>3.27</td>\n",
       "      <td>4.30</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>127</td>\n",
       "      <td>3.43</td>\n",
       "      <td>443.00</td>\n",
       "      <td>noun</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>alone</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.85</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>15735</td>\n",
       "      <td>2.86</td>\n",
       "      <td>480.00</td>\n",
       "      <td>noun</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>angst</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.50</td>\n",
       "      <td>5.76</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>47</td>\n",
       "      <td>1.96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>adj</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>annoyance</td>\n",
       "      <td>2.95</td>\n",
       "      <td>2.95</td>\n",
       "      <td>4.10</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>2.14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>noun</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         Word  MeanValence  ValenceStand  MeanArousal  type  \\\n",
       "0           0  abandonment         2.63          2.63         4.95     0   \n",
       "1           1         ache         3.27          3.27         4.30     0   \n",
       "2           2        alone         3.85          3.85         4.00     0   \n",
       "3           3        angst         3.50          3.50         5.76     0   \n",
       "4           4    annoyance         2.95          2.95         4.10     0   \n",
       "\n",
       "   letters  frequency  Concreteness     Img   pos Unnamed: 10  Unnamed: 11  \\\n",
       "0       11         49          2.54    3.48  noun         NaN          NaN   \n",
       "1        4        127          3.43  443.00  noun         NaN          NaN   \n",
       "2        5      15735          2.86  480.00  noun         NaN          NaN   \n",
       "3        5         47          1.96     NaN   adj         NaN          NaN   \n",
       "4        9         25          2.14     NaN  noun         NaN          NaN   \n",
       "\n",
       "   Unnamed: 12  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  "
      ]
     },
     "execution_count": 1012,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Stimuli/WordsListF.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1013,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>MeanValence</th>\n",
       "      <th>ValenceStand</th>\n",
       "      <th>MeanArousal</th>\n",
       "      <th>type</th>\n",
       "      <th>letters</th>\n",
       "      <th>frequency</th>\n",
       "      <th>Concreteness</th>\n",
       "      <th>pos</th>\n",
       "      <th>Imagability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>willingness</td>\n",
       "      <td>6.43</td>\n",
       "      <td>3.57</td>\n",
       "      <td>4.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.81</td>\n",
       "      <td>noun</td>\n",
       "      <td>3.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>winner</td>\n",
       "      <td>7.86</td>\n",
       "      <td>2.14</td>\n",
       "      <td>6.53</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1592.0</td>\n",
       "      <td>3.21</td>\n",
       "      <td>noun</td>\n",
       "      <td>4.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>wise</td>\n",
       "      <td>7.42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.46</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1452.0</td>\n",
       "      <td>1.97</td>\n",
       "      <td>adj</td>\n",
       "      <td>3.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>witty</td>\n",
       "      <td>7.25</td>\n",
       "      <td>2.75</td>\n",
       "      <td>5.65</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>2.21</td>\n",
       "      <td>adj</td>\n",
       "      <td>3.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>zest</td>\n",
       "      <td>6.76</td>\n",
       "      <td>3.24</td>\n",
       "      <td>5.41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2.27</td>\n",
       "      <td>noun</td>\n",
       "      <td>2.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Word  MeanValence  ValenceStand  MeanArousal  type  letters  \\\n",
       "340  willingness         6.43          3.57         4.25   1.0     11.0   \n",
       "341       winner         7.86          2.14         6.53   1.0      6.0   \n",
       "342         wise         7.42           NaN         4.46   1.0      4.0   \n",
       "343        witty         7.25          2.75         5.65   1.0      5.0   \n",
       "344         zest         6.76          3.24         5.41   1.0      4.0   \n",
       "\n",
       "     frequency  Concreteness   pos  Imagability  \n",
       "340       68.0          1.81  noun         3.16  \n",
       "341     1592.0          3.21  noun         4.64  \n",
       "342     1452.0          1.97   adj         3.46  \n",
       "343      163.0          2.21   adj         3.30  \n",
       "344       35.0          2.27  noun         2.78  "
      ]
     },
     "execution_count": 1013,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.merge(df_img_just_words, how = 'outer')\n",
    "df = df[['Word', 'MeanValence', 'ValenceStand', 'MeanArousal', 'type', 'letters', 'frequency', 'Concreteness', 'pos', 'Imagability']]\n",
    "df = df.drop_duplicates('Word') # we had a few repeats\n",
    "df = df[pd.notnull(df['Imagability'])]# we didn't include \"focus\" in the MTurk study, so img is blank\n",
    "df = df[pd.notnull(df['type'])]\n",
    "df = df[df.Word != 'bummer']\n",
    "df = df[df.Word != 'clingy']\n",
    "df = df[df.Word != 'comatose']\n",
    "df = df[df.Word != 'deadbeat']\n",
    "df = df[df.Word != 'faker']\n",
    "df = df[df.Word != 'hag']\n",
    "df = df[df.Word != 'lowlife']\n",
    "df = df[df.Word != 'mousy']\n",
    "df = df[df.Word != 'scumbag']\n",
    "df = df[df.Word != 'sleaze']\n",
    "df = df[df.Word != 'wannabe']\n",
    "df = df[df.Word != 'kisser']\n",
    "df = df[df.Word != 'longevity']\n",
    "df = df[df.Word != 'pizzazz']\n",
    "df = df[df.Word != 'upbeat']\n",
    "df = df[df.Word != 'angst']\n",
    "df = df[df.Word != 'nutcase']\n",
    "df = df[df.Word != 'newlywed'] # the LSA thing doesn't know these words...there's prob an easier way to do this...\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#gets two new random lists\n",
    "def getnewneglist():\n",
    "    sampled_dfneg = dfneg.sample(100)\n",
    "    return sampled_dfneg\n",
    "\n",
    "# creating a random sample of 100 positive words\n",
    "def getnewposlist():\n",
    "    sampled_dfpos = dfpos.sample(100)\n",
    "    return sampled_dfpos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# checks the ttest for the new lists given a column name\n",
    "def checknewsig(column_name):\n",
    "    return ttest_ind(b[column_name], a[column_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# makes a df with the p's and t's of the words\n",
    "def makepdf():\n",
    "    pchart = pd.DataFrame({'p':[checknewsig('letters').pvalue, \n",
    "                                   checknewsig('MeanArousal').pvalue, \n",
    "                                  checknewsig('frequency').pvalue, \n",
    "                                   checknewsig('Concreteness').pvalue,\n",
    "                                   checknewsig('Imagability').pvalue],\n",
    "                          't':[checknewsig('letters').statistic, \n",
    "                                   checknewsig('MeanArousal').statistic, \n",
    "                                  checknewsig('frequency').statistic, \n",
    "                                   checknewsig('Concreteness').statistic,\n",
    "                                  checknewsig('Imagability').statistic]}, \n",
    "                       index=['letters', 'MeanArousal', 'frequency','Concreteness', 'Imagability'])\n",
    "    return pchart\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# checks the given series to see if columns are > .05\n",
    "def checkpdf(x):\n",
    "    return x.loc['frequency', 'p'] > .05 and x.loc['MeanArousal','p'] > .05 and x.loc['letters','p'] > .05 and x.loc['Imagability','p'] > .001 and x.loc['Concreteness','p'] > .05\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# not using this anymore but keep for reference\n",
    "\n",
    "#def main():\n",
    "    #a = getnewneglist()\n",
    "    #b = getnewposlist()\n",
    "    #if checkpdf(makepdf()) == True:\n",
    "        #makepdf().to_csv('p_values.csv')\n",
    "        #a.append(b).to_csv('balanced_words.csv')\n",
    "    #else:\n",
    "        #a = getnewneglist()\n",
    "        #b = getnewposlist()\n",
    "        #return main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1201,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Words:\n",
      "Unnamed: 0       86.450000\n",
      "MeanValence       2.759400\n",
      "ValenceStand      2.825176\n",
      "MeanArousal       4.672900\n",
      "type              0.000000\n",
      "letters           7.280000\n",
      "frequency       739.640000\n",
      "Concreteness      2.583900\n",
      "Imagability       3.496400\n",
      "dtype: float64\n",
      "--------------------\n",
      "Positive Words:\n",
      "Unnamed: 0       257.480000\n",
      "MeanValence        7.162500\n",
      "ValenceStand       2.948101\n",
      "MeanArousal        4.655100\n",
      "type               1.000000\n",
      "letters            7.420000\n",
      "frequency       1233.210000\n",
      "Concreteness       2.453000\n",
      "Imagability        3.645600\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "ab = pd.read_csv('Stimuli/Word_options/balanced_words_option8_WORKING.csv')\n",
    "a = ab[ab.type == 0]\n",
    "b = ab[ab.type == 1]\n",
    "print ('Negative Words:')\n",
    "print (a.mean()) # negatives have a few more nouns\n",
    "print ('--------------------')\n",
    "print ('Positive Words:')\n",
    "print (b.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1202,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Words:\n",
      "count      100\n",
      "unique       2\n",
      "top       noun\n",
      "freq        58\n",
      "Name: pos, dtype: object\n",
      "--------------------\n",
      "Positive Words:\n",
      "count      100\n",
      "unique       2\n",
      "top       noun\n",
      "freq        54\n",
      "Name: pos, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# looking at part of speech....\n",
    "print ('Negative Words:')\n",
    "print (a.pos.describe())\n",
    "print ('--------------------')\n",
    "print ('Positive Words:')\n",
    "print (b.pos.describe()) # needed to add more adj to the negative list, balanced now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1203,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>letters</th>\n",
       "      <td>0.659180</td>\n",
       "      <td>0.441712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MeanArousal</th>\n",
       "      <td>0.881560</td>\n",
       "      <td>-0.149184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequency</th>\n",
       "      <td>0.174274</td>\n",
       "      <td>1.363496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Concreteness</th>\n",
       "      <td>0.218651</td>\n",
       "      <td>-1.234039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Imagability</th>\n",
       "      <td>0.121848</td>\n",
       "      <td>1.553721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     p         t\n",
       "letters       0.659180  0.441712\n",
       "MeanArousal   0.881560 -0.149184\n",
       "frequency     0.174274  1.363496\n",
       "Concreteness  0.218651 -1.234039\n",
       "Imagability   0.121848  1.553721"
      ]
     },
     "execution_count": 1203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "makepdf() # look at significance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at LSA\n",
    "\n",
    "http://lsa.colorado.edu/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1150,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add the negative LSA csv\n",
    "lsa = pd.read_csv('Stimuli/Word_options/option8_lsa_neg_WORKING.csv')\n",
    "values = lsa[lsa['Document']].values\n",
    "lower_triangular = values[np.tril_indices(values.shape[0], -1)]\n",
    "lsa = pd.DataFrame({'Neg': lower_triangular})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neg    4950\n",
       "Pos    4950\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add the positive LSA csv\n",
    "pos = pd.read_csv('Stimuli/Word_options/option8_lsa_pos_WORKING.csv')\n",
    "values = pos[pos['Document']].values\n",
    "lower_triangular = values[np.tril_indices(values.shape[0], -1)]\n",
    "lsa['Pos'] = lower_triangular\n",
    "lsa.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1197,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Neg</th>\n",
       "      <th>Pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4950.000000</td>\n",
       "      <td>4950.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.105190</td>\n",
       "      <td>0.108180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.100247</td>\n",
       "      <td>0.097665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.150000</td>\n",
       "      <td>-0.140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.740000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Neg          Pos\n",
       "count  4950.000000  4950.000000\n",
       "mean      0.105190     0.108180\n",
       "std       0.100247     0.097665\n",
       "min      -0.150000    -0.140000\n",
       "25%       0.030000     0.040000\n",
       "50%       0.090000     0.090000\n",
       "75%       0.160000     0.160000\n",
       "max       0.620000     0.740000"
      ]
     },
     "execution_count": 1197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some descriptives\n",
    "lsa.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-1.5030186968158052, pvalue=0.13286612570152892)"
      ]
     },
     "execution_count": 1198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_ind(lsa['Neg'], lsa['Pos']) # are they different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
